{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweets = pd.read_csv('data/tweets/processed_all_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>token</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>filtered_tokenized_text</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-29 02:18:35</td>\n",
       "      <td>first few days just 1k but going to 10k if no ...</td>\n",
       "      <td>['first', 'few', 'days', 'just', '1k', 'but', ...</td>\n",
       "      <td>['first', 'few', 'days', 'just', '1k', 'but', ...</td>\n",
       "      <td>['first', 'days', '1k', 'going', '10k', 'major...</td>\n",
       "      <td>first days 1k going 10k major note 10692 hopef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-29 02:11:30</td>\n",
       "      <td>good to ask yourself this often</td>\n",
       "      <td>['good', 'to', 'ask', 'yourself', 'this', 'oft...</td>\n",
       "      <td>['good', 'to', 'ask', 'yourself', 'this', 'oft...</td>\n",
       "      <td>['good', 'ask', 'often']</td>\n",
       "      <td>good ask often</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-29 02:11:12</td>\n",
       "      <td>agreed we recently made this change many an in...</td>\n",
       "      <td>['agreed', 'we', 'recently', 'made', 'this', '...</td>\n",
       "      <td>['agreed', 'we', 'recently', 'made', 'this', '...</td>\n",
       "      <td>['agreed', 'recently', 'made', 'change', 'many...</td>\n",
       "      <td>agreed recently made change many intense effor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-28 23:51:49</td>\n",
       "      <td>this will happen again just a matter of time</td>\n",
       "      <td>['this', 'will', 'happen', 'again', 'just', 'a...</td>\n",
       "      <td>['this', 'will', 'happen', 'again', 'just', 'a...</td>\n",
       "      <td>['happen', 'matter', 'time']</td>\n",
       "      <td>happen matter time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-28 22:54:36</td>\n",
       "      <td>the swoop of the x is meant to represent the a...</td>\n",
       "      <td>['the', 'swoop', 'of', 'the', 'x', 'is', 'mean...</td>\n",
       "      <td>['the', 'swoop', 'of', 'the', 'x', 'is', 'mean...</td>\n",
       "      <td>['swoop', 'x', 'meant', 'represent', 'arc', 'o...</td>\n",
       "      <td>swoop x meant represent arc orbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958</th>\n",
       "      <td>2018-01-07 03:00:48</td>\n",
       "      <td>near 405</td>\n",
       "      <td>['near', '405']</td>\n",
       "      <td>['near', '405']</td>\n",
       "      <td>['near', '405']</td>\n",
       "      <td>near 405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12959</th>\n",
       "      <td>2018-01-07 02:33:02</td>\n",
       "      <td>put an old school roller rock restaurant at on...</td>\n",
       "      <td>['put', 'an', 'old', 'school', 'roller', 'rock...</td>\n",
       "      <td>['put', 'an', 'old', 'school', 'roller', 'rock...</td>\n",
       "      <td>['put', 'old', 'school', 'roller', 'rock', 're...</td>\n",
       "      <td>put old school roller rock restaurant one new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12960</th>\n",
       "      <td>2018-01-05 00:30:00</td>\n",
       "      <td>falcon heavy goes vertical</td>\n",
       "      <td>['falcon', 'heavy', 'goes', 'vertical']</td>\n",
       "      <td>['falcon', 'heavy', 'goes', 'vertical']</td>\n",
       "      <td>['falcon', 'heavy', 'goes', 'vertical']</td>\n",
       "      <td>falcon heavy goes vertical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12961</th>\n",
       "      <td>2018-01-03 08:22:31</td>\n",
       "      <td>a neural net to detect rain no rain or sun are...</td>\n",
       "      <td>['a', 'neural', 'net', 'to', 'detect', 'rain',...</td>\n",
       "      <td>['a', 'neural', 'net', 'to', 'detect', 'rain',...</td>\n",
       "      <td>['neural', 'net', 'detect', 'rain', 'rain', 's...</td>\n",
       "      <td>neural net detect rain rain sun patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12962</th>\n",
       "      <td>2018-01-03 05:38:16</td>\n",
       "      <td>come work at the biggest most advanced factory...</td>\n",
       "      <td>['come', 'work', 'at', 'the', 'biggest', 'most...</td>\n",
       "      <td>['come', 'work', 'at', 'the', 'biggest', 'most...</td>\n",
       "      <td>['come', 'work', 'biggest', 'advanced', 'facto...</td>\n",
       "      <td>come work biggest advanced factory earth river...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12963 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime                                               text  \\\n",
       "0      2022-08-29 02:18:35  first few days just 1k but going to 10k if no ...   \n",
       "1      2022-08-29 02:11:30                    good to ask yourself this often   \n",
       "2      2022-08-29 02:11:12  agreed we recently made this change many an in...   \n",
       "3      2022-08-28 23:51:49       this will happen again just a matter of time   \n",
       "4      2022-08-28 22:54:36  the swoop of the x is meant to represent the a...   \n",
       "...                    ...                                                ...   \n",
       "12958  2018-01-07 03:00:48                                           near 405   \n",
       "12959  2018-01-07 02:33:02  put an old school roller rock restaurant at on...   \n",
       "12960  2018-01-05 00:30:00                         falcon heavy goes vertical   \n",
       "12961  2018-01-03 08:22:31  a neural net to detect rain no rain or sun are...   \n",
       "12962  2018-01-03 05:38:16  come work at the biggest most advanced factory...   \n",
       "\n",
       "                                                   token  \\\n",
       "0      ['first', 'few', 'days', 'just', '1k', 'but', ...   \n",
       "1      ['good', 'to', 'ask', 'yourself', 'this', 'oft...   \n",
       "2      ['agreed', 'we', 'recently', 'made', 'this', '...   \n",
       "3      ['this', 'will', 'happen', 'again', 'just', 'a...   \n",
       "4      ['the', 'swoop', 'of', 'the', 'x', 'is', 'mean...   \n",
       "...                                                  ...   \n",
       "12958                                    ['near', '405']   \n",
       "12959  ['put', 'an', 'old', 'school', 'roller', 'rock...   \n",
       "12960            ['falcon', 'heavy', 'goes', 'vertical']   \n",
       "12961  ['a', 'neural', 'net', 'to', 'detect', 'rain',...   \n",
       "12962  ['come', 'work', 'at', 'the', 'biggest', 'most...   \n",
       "\n",
       "                                          tokenized_text  \\\n",
       "0      ['first', 'few', 'days', 'just', '1k', 'but', ...   \n",
       "1      ['good', 'to', 'ask', 'yourself', 'this', 'oft...   \n",
       "2      ['agreed', 'we', 'recently', 'made', 'this', '...   \n",
       "3      ['this', 'will', 'happen', 'again', 'just', 'a...   \n",
       "4      ['the', 'swoop', 'of', 'the', 'x', 'is', 'mean...   \n",
       "...                                                  ...   \n",
       "12958                                    ['near', '405']   \n",
       "12959  ['put', 'an', 'old', 'school', 'roller', 'rock...   \n",
       "12960            ['falcon', 'heavy', 'goes', 'vertical']   \n",
       "12961  ['a', 'neural', 'net', 'to', 'detect', 'rain',...   \n",
       "12962  ['come', 'work', 'at', 'the', 'biggest', 'most...   \n",
       "\n",
       "                                 filtered_tokenized_text  \\\n",
       "0      ['first', 'days', '1k', 'going', '10k', 'major...   \n",
       "1                               ['good', 'ask', 'often']   \n",
       "2      ['agreed', 'recently', 'made', 'change', 'many...   \n",
       "3                           ['happen', 'matter', 'time']   \n",
       "4      ['swoop', 'x', 'meant', 'represent', 'arc', 'o...   \n",
       "...                                                  ...   \n",
       "12958                                    ['near', '405']   \n",
       "12959  ['put', 'old', 'school', 'roller', 'rock', 're...   \n",
       "12960            ['falcon', 'heavy', 'goes', 'vertical']   \n",
       "12961  ['neural', 'net', 'detect', 'rain', 'rain', 's...   \n",
       "12962  ['come', 'work', 'biggest', 'advanced', 'facto...   \n",
       "\n",
       "                                           filtered_text  \n",
       "0      first days 1k going 10k major note 10692 hopef...  \n",
       "1                                         good ask often  \n",
       "2      agreed recently made change many intense effor...  \n",
       "3                                     happen matter time  \n",
       "4                      swoop x meant represent arc orbit  \n",
       "...                                                  ...  \n",
       "12958                                           near 405  \n",
       "12959  put old school roller rock restaurant one new ...  \n",
       "12960                         falcon heavy goes vertical  \n",
       "12961            neural net detect rain rain sun patient  \n",
       "12962  come work biggest advanced factory earth river...  \n",
       "\n",
       "[12963 rows x 6 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\levit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'days', 'going', 'major', 'note', 'hopefully']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "\n",
    "data = tweets.filtered_text.values.tolist()\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.034*\"yes\" + 0.013*\"true\" + 0.010*\"soon\" + 0.010*\"thanks\" + 0.009*\"coming\" '\n",
      "  '+ 0.008*\"good\" + 0.007*\"earth\" + 0.007*\"year\" + 0.006*\"also\" + '\n",
      "  '0.006*\"starship\"'),\n",
      " (1,\n",
      "  '0.010*\"sure\" + 0.008*\"good\" + 0.007*\"like\" + 0.006*\"one\" + 0.005*\"best\" + '\n",
      "  '0.005*\"year\" + 0.005*\"time\" + 0.005*\"launch\" + 0.005*\"might\" + '\n",
      "  '0.004*\"many\"'),\n",
      " (2,\n",
      "  '0.010*\"people\" + 0.010*\"thats\" + 0.008*\"yeah\" + 0.007*\"car\" + 0.006*\"also\" '\n",
      "  '+ 0.006*\"day\" + 0.005*\"model\" + 0.005*\"time\" + 0.005*\"way\" + '\n",
      "  '0.005*\"interesting\"'),\n",
      " (3,\n",
      "  '0.015*\"exactly\" + 0.008*\"even\" + 0.008*\"great\" + 0.007*\"time\" + '\n",
      "  '0.007*\"work\" + 0.007*\"team\" + 0.006*\"would\" + 0.005*\"maybe\" + 0.005*\"go\" + '\n",
      "  '0.005*\"get\"'),\n",
      " (4,\n",
      "  '0.012*\"great\" + 0.010*\"good\" + 0.009*\"one\" + 0.008*\"true\" + 0.008*\"new\" + '\n",
      "  '0.008*\"production\" + 0.007*\"many\" + 0.007*\"starship\" + 0.006*\"still\" + '\n",
      "  '0.006*\"hard\"'),\n",
      " (5,\n",
      "  '0.009*\"much\" + 0.008*\"way\" + 0.006*\"would\" + 0.006*\"falcon\" + '\n",
      "  '0.006*\"probably\" + 0.005*\"life\" + 0.005*\"next\" + 0.005*\"major\" + '\n",
      "  '0.005*\"twitter\" + 0.005*\"enough\"'),\n",
      " (6,\n",
      "  '0.011*\"great\" + 0.011*\"much\" + 0.010*\"would\" + 0.008*\"get\" + 0.007*\"still\" '\n",
      "  '+ 0.007*\"people\" + 0.006*\"like\" + 0.006*\"sure\" + 0.006*\"need\" + '\n",
      "  '0.005*\"cost\"'),\n",
      " (7,\n",
      "  '0.009*\"great\" + 0.009*\"like\" + 0.008*\"would\" + 0.007*\"feed\" + 0.006*\"next\" '\n",
      "  '+ 0.005*\"starship\" + 0.005*\"engine\" + 0.005*\"dont\" + 0.005*\"production\" + '\n",
      "  '0.004*\"car\"'),\n",
      " (8,\n",
      "  '0.010*\"yes\" + 0.008*\"much\" + 0.007*\"would\" + 0.007*\"high\" + 0.006*\"maybe\" + '\n",
      "  '0.006*\"one\" + 0.005*\"good\" + 0.005*\"enough\" + 0.005*\"company\" + '\n",
      "  '0.005*\"exactly\"'),\n",
      " (9,\n",
      "  '0.018*\"good\" + 0.009*\"would\" + 0.009*\"make\" + 0.007*\"like\" + 0.006*\"dont\" + '\n",
      "  '0.006*\"yeah\" + 0.006*\"thanks\" + 0.006*\"one\" + 0.005*\"need\" + 0.005*\"work\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LdaMulticore' object has no attribute 'topics_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [105], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlda_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopics_values\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LdaMulticore' object has no attribute 'topics_values'"
     ]
    }
   ],
   "source": [
    "lda_model.topics_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit ('3.10.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e748b08df6639b92156e1f0a2e584fc605f942beb5319c4ded409ee9197cfce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
