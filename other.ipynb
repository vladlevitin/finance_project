{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-29 02:18:35</td>\n",
       "      <td>first few days just 1k but going to 10k if no ...</td>\n",
       "      <td>['first', 'few', 'days', 'just', '1k', 'but', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-29 02:11:30</td>\n",
       "      <td>good to ask yourself this often</td>\n",
       "      <td>['good', 'to', 'ask', 'yourself', 'this', 'oft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-29 02:11:12</td>\n",
       "      <td>agreed we recently made this change many an in...</td>\n",
       "      <td>['agreed', 'we', 'recently', 'made', 'this', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-28 23:51:49</td>\n",
       "      <td>this will happen again just a matter of time</td>\n",
       "      <td>['this', 'will', 'happen', 'again', 'just', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-28 22:54:36</td>\n",
       "      <td>the swoop of the x is meant to represent the a...</td>\n",
       "      <td>['the', 'swoop', 'of', 'the', 'x', 'is', 'mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13203</th>\n",
       "      <td>2018-01-07 03:00:48</td>\n",
       "      <td>near 405</td>\n",
       "      <td>['near', '405']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13204</th>\n",
       "      <td>2018-01-07 02:33:02</td>\n",
       "      <td>put an old school roller rock restaurant at on...</td>\n",
       "      <td>['put', 'an', 'old', 'school', 'roller', 'rock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13205</th>\n",
       "      <td>2018-01-05 00:30:00</td>\n",
       "      <td>falcon heavy goes vertical</td>\n",
       "      <td>['falcon', 'heavy', 'goes', 'vertical']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13206</th>\n",
       "      <td>2018-01-03 08:22:31</td>\n",
       "      <td>a neural net to detect rain no rain or sun are...</td>\n",
       "      <td>['a', 'neural', 'net', 'to', 'detect', 'rain',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13207</th>\n",
       "      <td>2018-01-03 05:38:16</td>\n",
       "      <td>come work at the biggest most advanced factory...</td>\n",
       "      <td>['come', 'work', 'at', 'the', 'biggest', 'most...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13208 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime                                               text  \\\n",
       "0      2022-08-29 02:18:35  first few days just 1k but going to 10k if no ...   \n",
       "1      2022-08-29 02:11:30                    good to ask yourself this often   \n",
       "2      2022-08-29 02:11:12  agreed we recently made this change many an in...   \n",
       "3      2022-08-28 23:51:49       this will happen again just a matter of time   \n",
       "4      2022-08-28 22:54:36  the swoop of the x is meant to represent the a...   \n",
       "...                    ...                                                ...   \n",
       "13203  2018-01-07 03:00:48                                           near 405   \n",
       "13204  2018-01-07 02:33:02  put an old school roller rock restaurant at on...   \n",
       "13205  2018-01-05 00:30:00                         falcon heavy goes vertical   \n",
       "13206  2018-01-03 08:22:31  a neural net to detect rain no rain or sun are...   \n",
       "13207  2018-01-03 05:38:16  come work at the biggest most advanced factory...   \n",
       "\n",
       "                                                   token  \n",
       "0      ['first', 'few', 'days', 'just', '1k', 'but', ...  \n",
       "1      ['good', 'to', 'ask', 'yourself', 'this', 'oft...  \n",
       "2      ['agreed', 'we', 'recently', 'made', 'this', '...  \n",
       "3      ['this', 'will', 'happen', 'again', 'just', 'a...  \n",
       "4      ['the', 'swoop', 'of', 'the', 'x', 'is', 'mean...  \n",
       "...                                                  ...  \n",
       "13203                                    ['near', '405']  \n",
       "13204  ['put', 'an', 'old', 'school', 'roller', 'rock...  \n",
       "13205            ['falcon', 'heavy', 'goes', 'vertical']  \n",
       "13206  ['a', 'neural', 'net', 'to', 'detect', 'rain',...  \n",
       "13207  ['come', 'work', 'at', 'the', 'biggest', 'most...  \n",
       "\n",
       "[13208 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweets = pd.read_csv('data/tweets/all_tweets.csv')\n",
    "\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\levit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>token</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>filtered_tokenized_text</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-29 02:18:35</td>\n",
       "      <td>first few days just 1k but going to 10k if no ...</td>\n",
       "      <td>['first', 'few', 'days', 'just', '1k', 'but', ...</td>\n",
       "      <td>[first, few, days, just, 1k, but, going, to, 1...</td>\n",
       "      <td>[first, days, 1k, going, 10k, major, note, 106...</td>\n",
       "      <td>first days 1k going 10k major note 10692 hopef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-29 02:11:30</td>\n",
       "      <td>good to ask yourself this often</td>\n",
       "      <td>['good', 'to', 'ask', 'yourself', 'this', 'oft...</td>\n",
       "      <td>[good, to, ask, yourself, this, often]</td>\n",
       "      <td>[good, ask, often]</td>\n",
       "      <td>good ask often</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-29 02:11:12</td>\n",
       "      <td>agreed we recently made this change many an in...</td>\n",
       "      <td>['agreed', 'we', 'recently', 'made', 'this', '...</td>\n",
       "      <td>[agreed, we, recently, made, this, change, man...</td>\n",
       "      <td>[agreed, recently, made, change, many, intense...</td>\n",
       "      <td>agreed recently made change many intense effor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-28 23:51:49</td>\n",
       "      <td>this will happen again just a matter of time</td>\n",
       "      <td>['this', 'will', 'happen', 'again', 'just', 'a...</td>\n",
       "      <td>[this, will, happen, again, just, a, matter, o...</td>\n",
       "      <td>[happen, matter, time]</td>\n",
       "      <td>happen matter time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-28 22:54:36</td>\n",
       "      <td>the swoop of the x is meant to represent the a...</td>\n",
       "      <td>['the', 'swoop', 'of', 'the', 'x', 'is', 'mean...</td>\n",
       "      <td>[the, swoop, of, the, x, is, meant, to, repres...</td>\n",
       "      <td>[swoop, x, meant, represent, arc, orbit]</td>\n",
       "      <td>swoop x meant represent arc orbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13203</th>\n",
       "      <td>2018-01-07 03:00:48</td>\n",
       "      <td>near 405</td>\n",
       "      <td>['near', '405']</td>\n",
       "      <td>[near, 405]</td>\n",
       "      <td>[near, 405]</td>\n",
       "      <td>near 405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13204</th>\n",
       "      <td>2018-01-07 02:33:02</td>\n",
       "      <td>put an old school roller rock restaurant at on...</td>\n",
       "      <td>['put', 'an', 'old', 'school', 'roller', 'rock...</td>\n",
       "      <td>[put, an, old, school, roller, rock, restauran...</td>\n",
       "      <td>[put, old, school, roller, rock, restaurant, o...</td>\n",
       "      <td>put old school roller rock restaurant one new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13205</th>\n",
       "      <td>2018-01-05 00:30:00</td>\n",
       "      <td>falcon heavy goes vertical</td>\n",
       "      <td>['falcon', 'heavy', 'goes', 'vertical']</td>\n",
       "      <td>[falcon, heavy, goes, vertical]</td>\n",
       "      <td>[falcon, heavy, goes, vertical]</td>\n",
       "      <td>falcon heavy goes vertical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13206</th>\n",
       "      <td>2018-01-03 08:22:31</td>\n",
       "      <td>a neural net to detect rain no rain or sun are...</td>\n",
       "      <td>['a', 'neural', 'net', 'to', 'detect', 'rain',...</td>\n",
       "      <td>[a, neural, net, to, detect, rain, no, rain, o...</td>\n",
       "      <td>[neural, net, detect, rain, rain, sun, patient]</td>\n",
       "      <td>neural net detect rain rain sun patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13207</th>\n",
       "      <td>2018-01-03 05:38:16</td>\n",
       "      <td>come work at the biggest most advanced factory...</td>\n",
       "      <td>['come', 'work', 'at', 'the', 'biggest', 'most...</td>\n",
       "      <td>[come, work, at, the, biggest, most, advanced,...</td>\n",
       "      <td>[come, work, biggest, advanced, factory, earth...</td>\n",
       "      <td>come work biggest advanced factory earth river...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13208 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime                                               text  \\\n",
       "0      2022-08-29 02:18:35  first few days just 1k but going to 10k if no ...   \n",
       "1      2022-08-29 02:11:30                    good to ask yourself this often   \n",
       "2      2022-08-29 02:11:12  agreed we recently made this change many an in...   \n",
       "3      2022-08-28 23:51:49       this will happen again just a matter of time   \n",
       "4      2022-08-28 22:54:36  the swoop of the x is meant to represent the a...   \n",
       "...                    ...                                                ...   \n",
       "13203  2018-01-07 03:00:48                                           near 405   \n",
       "13204  2018-01-07 02:33:02  put an old school roller rock restaurant at on...   \n",
       "13205  2018-01-05 00:30:00                         falcon heavy goes vertical   \n",
       "13206  2018-01-03 08:22:31  a neural net to detect rain no rain or sun are...   \n",
       "13207  2018-01-03 05:38:16  come work at the biggest most advanced factory...   \n",
       "\n",
       "                                                   token  \\\n",
       "0      ['first', 'few', 'days', 'just', '1k', 'but', ...   \n",
       "1      ['good', 'to', 'ask', 'yourself', 'this', 'oft...   \n",
       "2      ['agreed', 'we', 'recently', 'made', 'this', '...   \n",
       "3      ['this', 'will', 'happen', 'again', 'just', 'a...   \n",
       "4      ['the', 'swoop', 'of', 'the', 'x', 'is', 'mean...   \n",
       "...                                                  ...   \n",
       "13203                                    ['near', '405']   \n",
       "13204  ['put', 'an', 'old', 'school', 'roller', 'rock...   \n",
       "13205            ['falcon', 'heavy', 'goes', 'vertical']   \n",
       "13206  ['a', 'neural', 'net', 'to', 'detect', 'rain',...   \n",
       "13207  ['come', 'work', 'at', 'the', 'biggest', 'most...   \n",
       "\n",
       "                                          tokenized_text  \\\n",
       "0      [first, few, days, just, 1k, but, going, to, 1...   \n",
       "1                 [good, to, ask, yourself, this, often]   \n",
       "2      [agreed, we, recently, made, this, change, man...   \n",
       "3      [this, will, happen, again, just, a, matter, o...   \n",
       "4      [the, swoop, of, the, x, is, meant, to, repres...   \n",
       "...                                                  ...   \n",
       "13203                                        [near, 405]   \n",
       "13204  [put, an, old, school, roller, rock, restauran...   \n",
       "13205                    [falcon, heavy, goes, vertical]   \n",
       "13206  [a, neural, net, to, detect, rain, no, rain, o...   \n",
       "13207  [come, work, at, the, biggest, most, advanced,...   \n",
       "\n",
       "                                 filtered_tokenized_text  \\\n",
       "0      [first, days, 1k, going, 10k, major, note, 106...   \n",
       "1                                     [good, ask, often]   \n",
       "2      [agreed, recently, made, change, many, intense...   \n",
       "3                                 [happen, matter, time]   \n",
       "4               [swoop, x, meant, represent, arc, orbit]   \n",
       "...                                                  ...   \n",
       "13203                                        [near, 405]   \n",
       "13204  [put, old, school, roller, rock, restaurant, o...   \n",
       "13205                    [falcon, heavy, goes, vertical]   \n",
       "13206    [neural, net, detect, rain, rain, sun, patient]   \n",
       "13207  [come, work, biggest, advanced, factory, earth...   \n",
       "\n",
       "                                           filtered_text  \n",
       "0      first days 1k going 10k major note 10692 hopef...  \n",
       "1                                         good ask often  \n",
       "2      agreed recently made change many intense effor...  \n",
       "3                                     happen matter time  \n",
       "4                      swoop x meant represent arc orbit  \n",
       "...                                                  ...  \n",
       "13203                                           near 405  \n",
       "13204  put old school roller rock restaurant one new ...  \n",
       "13205                         falcon heavy goes vertical  \n",
       "13206            neural net detect rain rain sun patient  \n",
       "13207  come work biggest advanced factory earth river...  \n",
       "\n",
       "[13208 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['tokenized_text']= tweets['text'].apply(word_tokenize)\n",
    "\n",
    "tweets['filtered_tokenized_text']= tweets['tokenized_text'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "\n",
    "tweets['filtered_text'] = tweets['filtered_tokenized_text'].apply((\" \").join)\n",
    "\n",
    "tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('data/tweets/processed_all_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>token</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>filtered_tokenized_text</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-29 02:18:35</td>\n",
       "      <td>first few days just 1k but going to 10k if no ...</td>\n",
       "      <td>['first', 'few', 'days', 'just', '1k', 'but', ...</td>\n",
       "      <td>['first', 'few', 'days', 'just', '1k', 'but', ...</td>\n",
       "      <td>['first', 'days', '1k', 'going', '10k', 'major...</td>\n",
       "      <td>first days 1k going 10k major note 10692 hopef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-29 02:11:30</td>\n",
       "      <td>good to ask yourself this often</td>\n",
       "      <td>['good', 'to', 'ask', 'yourself', 'this', 'oft...</td>\n",
       "      <td>['good', 'to', 'ask', 'yourself', 'this', 'oft...</td>\n",
       "      <td>['good', 'ask', 'often']</td>\n",
       "      <td>good ask often</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-29 02:11:12</td>\n",
       "      <td>agreed we recently made this change many an in...</td>\n",
       "      <td>['agreed', 'we', 'recently', 'made', 'this', '...</td>\n",
       "      <td>['agreed', 'we', 'recently', 'made', 'this', '...</td>\n",
       "      <td>['agreed', 'recently', 'made', 'change', 'many...</td>\n",
       "      <td>agreed recently made change many intense effor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-28 23:51:49</td>\n",
       "      <td>this will happen again just a matter of time</td>\n",
       "      <td>['this', 'will', 'happen', 'again', 'just', 'a...</td>\n",
       "      <td>['this', 'will', 'happen', 'again', 'just', 'a...</td>\n",
       "      <td>['happen', 'matter', 'time']</td>\n",
       "      <td>happen matter time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-28 22:54:36</td>\n",
       "      <td>the swoop of the x is meant to represent the a...</td>\n",
       "      <td>['the', 'swoop', 'of', 'the', 'x', 'is', 'mean...</td>\n",
       "      <td>['the', 'swoop', 'of', 'the', 'x', 'is', 'mean...</td>\n",
       "      <td>['swoop', 'x', 'meant', 'represent', 'arc', 'o...</td>\n",
       "      <td>swoop x meant represent arc orbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958</th>\n",
       "      <td>2018-01-07 03:00:48</td>\n",
       "      <td>near 405</td>\n",
       "      <td>['near', '405']</td>\n",
       "      <td>['near', '405']</td>\n",
       "      <td>['near', '405']</td>\n",
       "      <td>near 405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12959</th>\n",
       "      <td>2018-01-07 02:33:02</td>\n",
       "      <td>put an old school roller rock restaurant at on...</td>\n",
       "      <td>['put', 'an', 'old', 'school', 'roller', 'rock...</td>\n",
       "      <td>['put', 'an', 'old', 'school', 'roller', 'rock...</td>\n",
       "      <td>['put', 'old', 'school', 'roller', 'rock', 're...</td>\n",
       "      <td>put old school roller rock restaurant one new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12960</th>\n",
       "      <td>2018-01-05 00:30:00</td>\n",
       "      <td>falcon heavy goes vertical</td>\n",
       "      <td>['falcon', 'heavy', 'goes', 'vertical']</td>\n",
       "      <td>['falcon', 'heavy', 'goes', 'vertical']</td>\n",
       "      <td>['falcon', 'heavy', 'goes', 'vertical']</td>\n",
       "      <td>falcon heavy goes vertical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12961</th>\n",
       "      <td>2018-01-03 08:22:31</td>\n",
       "      <td>a neural net to detect rain no rain or sun are...</td>\n",
       "      <td>['a', 'neural', 'net', 'to', 'detect', 'rain',...</td>\n",
       "      <td>['a', 'neural', 'net', 'to', 'detect', 'rain',...</td>\n",
       "      <td>['neural', 'net', 'detect', 'rain', 'rain', 's...</td>\n",
       "      <td>neural net detect rain rain sun patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12962</th>\n",
       "      <td>2018-01-03 05:38:16</td>\n",
       "      <td>come work at the biggest most advanced factory...</td>\n",
       "      <td>['come', 'work', 'at', 'the', 'biggest', 'most...</td>\n",
       "      <td>['come', 'work', 'at', 'the', 'biggest', 'most...</td>\n",
       "      <td>['come', 'work', 'biggest', 'advanced', 'facto...</td>\n",
       "      <td>come work biggest advanced factory earth river...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12963 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime                                               text  \\\n",
       "0      2022-08-29 02:18:35  first few days just 1k but going to 10k if no ...   \n",
       "1      2022-08-29 02:11:30                    good to ask yourself this often   \n",
       "2      2022-08-29 02:11:12  agreed we recently made this change many an in...   \n",
       "3      2022-08-28 23:51:49       this will happen again just a matter of time   \n",
       "4      2022-08-28 22:54:36  the swoop of the x is meant to represent the a...   \n",
       "...                    ...                                                ...   \n",
       "12958  2018-01-07 03:00:48                                           near 405   \n",
       "12959  2018-01-07 02:33:02  put an old school roller rock restaurant at on...   \n",
       "12960  2018-01-05 00:30:00                         falcon heavy goes vertical   \n",
       "12961  2018-01-03 08:22:31  a neural net to detect rain no rain or sun are...   \n",
       "12962  2018-01-03 05:38:16  come work at the biggest most advanced factory...   \n",
       "\n",
       "                                                   token  \\\n",
       "0      ['first', 'few', 'days', 'just', '1k', 'but', ...   \n",
       "1      ['good', 'to', 'ask', 'yourself', 'this', 'oft...   \n",
       "2      ['agreed', 'we', 'recently', 'made', 'this', '...   \n",
       "3      ['this', 'will', 'happen', 'again', 'just', 'a...   \n",
       "4      ['the', 'swoop', 'of', 'the', 'x', 'is', 'mean...   \n",
       "...                                                  ...   \n",
       "12958                                    ['near', '405']   \n",
       "12959  ['put', 'an', 'old', 'school', 'roller', 'rock...   \n",
       "12960            ['falcon', 'heavy', 'goes', 'vertical']   \n",
       "12961  ['a', 'neural', 'net', 'to', 'detect', 'rain',...   \n",
       "12962  ['come', 'work', 'at', 'the', 'biggest', 'most...   \n",
       "\n",
       "                                          tokenized_text  \\\n",
       "0      ['first', 'few', 'days', 'just', '1k', 'but', ...   \n",
       "1      ['good', 'to', 'ask', 'yourself', 'this', 'oft...   \n",
       "2      ['agreed', 'we', 'recently', 'made', 'this', '...   \n",
       "3      ['this', 'will', 'happen', 'again', 'just', 'a...   \n",
       "4      ['the', 'swoop', 'of', 'the', 'x', 'is', 'mean...   \n",
       "...                                                  ...   \n",
       "12958                                    ['near', '405']   \n",
       "12959  ['put', 'an', 'old', 'school', 'roller', 'rock...   \n",
       "12960            ['falcon', 'heavy', 'goes', 'vertical']   \n",
       "12961  ['a', 'neural', 'net', 'to', 'detect', 'rain',...   \n",
       "12962  ['come', 'work', 'at', 'the', 'biggest', 'most...   \n",
       "\n",
       "                                 filtered_tokenized_text  \\\n",
       "0      ['first', 'days', '1k', 'going', '10k', 'major...   \n",
       "1                               ['good', 'ask', 'often']   \n",
       "2      ['agreed', 'recently', 'made', 'change', 'many...   \n",
       "3                           ['happen', 'matter', 'time']   \n",
       "4      ['swoop', 'x', 'meant', 'represent', 'arc', 'o...   \n",
       "...                                                  ...   \n",
       "12958                                    ['near', '405']   \n",
       "12959  ['put', 'old', 'school', 'roller', 'rock', 're...   \n",
       "12960            ['falcon', 'heavy', 'goes', 'vertical']   \n",
       "12961  ['neural', 'net', 'detect', 'rain', 'rain', 's...   \n",
       "12962  ['come', 'work', 'biggest', 'advanced', 'facto...   \n",
       "\n",
       "                                           filtered_text  \n",
       "0      first days 1k going 10k major note 10692 hopef...  \n",
       "1                                         good ask often  \n",
       "2      agreed recently made change many intense effor...  \n",
       "3                                     happen matter time  \n",
       "4                      swoop x meant represent arc orbit  \n",
       "...                                                  ...  \n",
       "12958                                           near 405  \n",
       "12959  put old school roller rock restaurant one new ...  \n",
       "12960                         falcon heavy goes vertical  \n",
       "12961            neural net detect rain rain sun patient  \n",
       "12962  come work biggest advanced factory earth river...  \n",
       "\n",
       "[12963 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('data/tweets/processed_all_tweets.csv')\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x223d610f940>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "long_string = ','.join(list(tweets['filtered_text'].values))\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=5000, contour_color='steelblue', width=800, height=800)\n",
    "\n",
    "wordcloud.generate(long_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "    \n",
    "common_words = get_top_n_words(tweets.filtered_text, 20)\n",
    "unigram = pd.DataFrame(common_words, columns = ['unigram' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>time</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>car</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>high</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>make</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>people</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yeah</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>work</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>starship</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>exactly</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>probably</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>year</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>production</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>new</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>model</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sure</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unigram  count\n",
       "0          yes    570\n",
       "1         good    489\n",
       "2        great    449\n",
       "3         like    411\n",
       "4         true    336\n",
       "5         time    315\n",
       "6          car    309\n",
       "7         high    296\n",
       "8         make    289\n",
       "9       people    289\n",
       "10        yeah    286\n",
       "11        work    264\n",
       "12    starship    264\n",
       "13     exactly    261\n",
       "14    probably    256\n",
       "15        year    254\n",
       "16  production    247\n",
       "17         new    237\n",
       "18       model    236\n",
       "19        sure    235"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(3,3),stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in      vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_trigram(tweets.filtered_text, 10)\n",
    "trigram = pd.DataFrame(common_words, columns = ['trigram' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watch falcon launch</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>starship super heavy</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great work team</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>super heavy booster</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>people dont know</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>team great work</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>falcon launch 53</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>launch 53 orbit</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>falcon 9s stage</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>easy production hard</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                trigram  count\n",
       "0   watch falcon launch     17\n",
       "1  starship super heavy     13\n",
       "2       great work team     12\n",
       "3   super heavy booster      8\n",
       "4      people dont know      8\n",
       "5       team great work      7\n",
       "6      falcon launch 53      6\n",
       "7       launch 53 orbit      6\n",
       "8       falcon 9s stage      6\n",
       "9  easy production hard      6"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12963x3174 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 55085 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "vectorizer = CountVectorizer(\n",
    "analyzer='word',       \n",
    "min_df=3,# minimum required occurences of a word \n",
    "stop_words='english',# remove stop words\n",
    "lowercase=True,# convert all words to lowercase\n",
    "token_pattern='[a-zA-Z0-9]{3,}',# num chars > 3\n",
    "max_features=5000,# max number of unique words\n",
    "                            )\n",
    "data_matrix = vectorizer.fit_transform(tweets.filtered_text)\n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(\n",
    "    n_components=10, # Number of topics\n",
    "    learning_method='online',\n",
    "    random_state=20,       \n",
    "    n_jobs = -1 )\n",
    "\n",
    "\n",
    "lda_output = lda_model.fit_transform(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\pyLDAvis\\_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "perplexity must be less than n_samples",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [87], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39menable_notebook()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mpyLDAvis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlda_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtsne\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\pyLDAvis\\sklearn.py:95\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(lda_model, dtm, vectorizer, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39m\"\"\"Create Prepared Data from sklearn's LatentDirichletAllocation and CountVectorizer.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mSee `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     94\u001b[0m opts \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39mmerge(_extract_data(lda_model, dtm, vectorizer), kwargs)\n\u001b[1;32m---> 95\u001b[0m \u001b[39mreturn\u001b[39;00m pyLDAvis\u001b[39m.\u001b[39mprepare(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopts)\n",
      "File \u001b[1;32mc:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\pyLDAvis\\_prepare.py:443\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001b[0m\n\u001b[0;32m    439\u001b[0m topic_info \u001b[39m=\u001b[39m _topic_info(topic_term_dists, topic_proportion,\n\u001b[0;32m    440\u001b[0m                          term_frequency, term_topic_freq, vocab, lambda_step, R,\n\u001b[0;32m    441\u001b[0m                          n_jobs, start_index)\n\u001b[0;32m    442\u001b[0m token_table \u001b[39m=\u001b[39m _token_table(topic_info, term_topic_freq, vocab, term_frequency, start_index)\n\u001b[1;32m--> 443\u001b[0m topic_coordinates \u001b[39m=\u001b[39m _topic_coordinates(mds, topic_term_dists, topic_proportion, start_index)\n\u001b[0;32m    444\u001b[0m client_topic_order \u001b[39m=\u001b[39m [x \u001b[39m+\u001b[39m start_index \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m topic_order]\n\u001b[0;32m    446\u001b[0m \u001b[39mreturn\u001b[39;00m PreparedData(topic_coordinates, topic_info,\n\u001b[0;32m    447\u001b[0m                     token_table, R, lambda_step, plot_opts, client_topic_order)\n",
      "File \u001b[1;32mc:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\pyLDAvis\\_prepare.py:192\u001b[0m, in \u001b[0;36m_topic_coordinates\u001b[1;34m(mds, topic_term_dists, topic_proportion, start_index)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_topic_coordinates\u001b[39m(mds, topic_term_dists, topic_proportion, start_index\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m    191\u001b[0m     K \u001b[39m=\u001b[39m topic_term_dists\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 192\u001b[0m     mds_res \u001b[39m=\u001b[39m mds(topic_term_dists)\n\u001b[0;32m    193\u001b[0m     \u001b[39massert\u001b[39;00m mds_res\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (K, \u001b[39m2\u001b[39m)\n\u001b[0;32m    194\u001b[0m     mds_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m: mds_res[:, \u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m: mds_res[:, \u001b[39m1\u001b[39m],\n\u001b[0;32m    195\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mtopics\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mrange\u001b[39m(start_index, K \u001b[39m+\u001b[39m start_index),\n\u001b[0;32m    196\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFreq\u001b[39m\u001b[39m'\u001b[39m: topic_proportion \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\pyLDAvis\\_prepare.py:167\u001b[0m, in \u001b[0;36mjs_TSNE\u001b[1;34m(distributions, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m dist_matrix \u001b[39m=\u001b[39m squareform(pdist(distributions, metric\u001b[39m=\u001b[39m_jensen_shannon))\n\u001b[0;32m    166\u001b[0m model \u001b[39m=\u001b[39m TSNE(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mprecomputed\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 167\u001b[0m \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit_transform(dist_matrix)\n",
      "File \u001b[1;32mc:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1122\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1103\u001b[0m     \u001b[39m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m \n\u001b[0;32m   1105\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[39m        Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1122\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params_vs_input(X)\n\u001b[0;32m   1123\u001b[0m     embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X)\n\u001b[0;32m   1124\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ \u001b[39m=\u001b[39m embedding\n",
      "File \u001b[1;32mc:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:793\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_params_vs_input\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperplexity \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m--> 793\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mperplexity must be less than n_samples\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: perplexity must be less than n_samples"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda_model, data_matrix, vectorizer, mds='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['propellant', 'close', 'absolutely', 'fast', 'extremely', 'change', 'wow', 'amazing', 'work', 'sure']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['china', 'build', 'end', 'super', 'day', 'working', 'lot', 'hard', 'thanks', 'thats']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['test', 'heavy', 'orbit', 'future', 'rocket', 'engine', 'falcon', 'launch', 'probably', 'starship']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['said', 'support', 'low', 'problem', 'times', 'long', 'people', 'right', 'production', 'good']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['cool', 'love', 'point', 'best', 'team', 'new', 'way', 'maybe', 'model', 'great']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5:\n",
      "['buy', 'bad', 'getting', 'ago', 'year', 'real', 'know', 'big', 'coming', 'yes']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6:\n",
      "['energy', 'people', 'power', 'going', 'use', 'think', 'better', 'high', 'dont', 'make']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7:\n",
      "['early', 'version', 'safety', 'later', 'release', 'beta', 'mass', 'week', 'need', 'true']\n",
      "\n",
      "\n",
      "Top 10 words for topic #8:\n",
      "['air', 'doesnt', 'company', 'little', 'pretty', 'earth', 'car', 'soon', 'exactly', 'yeah']\n",
      "\n",
      "\n",
      "Top 10 words for topic #9:\n",
      "['order', 'idea', 'pressure', 'fun', 'definitely', 'want', 'feed', 'actually', 'time', 'like']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\levit\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(lda_model.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit ('3.10.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e748b08df6639b92156e1f0a2e584fc605f942beb5319c4ded409ee9197cfce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
